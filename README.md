# Cost-Optimized Inference Engine

Intelligent inference orchestration with dynamic batching, KV-cache optimization, semantic coalescing, and cost-aware routing.

## Quickstart

1) Install dependencies (Poetry suggested) and run:

```bash
make dev
```

2) Open API docs at `http://localhost:8000/docs`.

## Features

- Adaptive and semantic batching
- Prefix, exact, and semantic caching
- Cost-aware model routing
- Structured logging and metrics

## Project Layout

See `docs/` and blueprint for full design.
